# 使用 Docker 部署 Ollama

## 1 检查 `nvidia-smi` 是否正常

> 要使用 `nvidia-smi` 需要先安装Nvidia驱动
>
> 安装命令: `sudo apt-get install nvidia-driver-<version>`
>
> 安装文档 [地址](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation)

```shell
➜ nvidia-smi
Fri Mar 28 02:44:18 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.86.17              Driver Version: 572.47         CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4060 ...    On  |   00000000:01:00.0  On |                  N/A |
| N/A   43C    P5              8W /  115W |    1846MiB /   8188MiB |      9%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```

## 2 检查 `Docker` 是否安装

> Docker 安装命令: `sudo apt install docker.io`

```shell
➜ docker -v
Docker version 28.0.1, build 068a01e
```

## 3 拉取 `ollama` 镜像

> 要拉去指定版本使用 `docker pull docker.1ms.run/ollama/ollama:<version>`

```shell
➜ docker pull docker.1ms.run/ollama/ollama
Using default tag: latest
latest: Pulling from ollama/ollama
d9802f032d67: Already exists
161508c220d5: Already exists
a5fe86995597: Pull complete
dfe8fac24641: Pull complete
Digest: sha256:74a0929e1e082a09e4fdeef8594b8f4537f661366a04080e600c90ea9f712721
Status: Downloaded newer image for docker.1ms.run/ollama/ollama:latest
docker.1ms.run/ollama/ollama:latest
```

## 4 启动 `ollama` 镜像

> 启动命令 `docker run -d -p <本地端口>:11434 --name <容器名称> docker.1ms.run/ollama/ollama`
>
> `-p 本地端口:容器端口`: 指定端口映射 (ollama默认11434)
>
> `-d`: 后台运行
>
> `--name`: 随便

完整命令示例

```shell
docker run -d -p 11434:11434 --name ollama docker.1ms.run/ollama/ollama
```

运行效果

```shell
➜ docker run -d -p 11434:11434 --name ollama docker.1ms.run/ollama/ollama
latest: Pulling from ollama/ollama
Digest: sha256:74a0929e1e082a09e4fdeef8594b8f4537f661366a04080e600c90ea9f712721
7ea988ec38c46cf2c244ba01c91f1a8e8a2a027511f770735de9987547f0b9ab
```

使用 `docker ps` 查看是否运行成功

```shell
➜ docker ps
CONTAINER ID   IMAGE                          COMMAND               CREATED          STATUS          PORTS                      NAMES
7ea988ec38c4   docker.1ms.run/ollama/ollama   "/bin/ollama serve"   27 seconds ago   Up 26 seconds   0.0.0.0:11434->11434/tcp   ollama
```

## 5 拉取并运行指定模型

模型名称可以在 <https://ollama.com/library> 查看

### 5.1 进入 `ollama` 容器

```shell
# 命令：docker exec -it <容器名称> bash
➜ docker exec -it ollama bash
root@7ea988ec38c4:/#
```

### 5.2 拉取并运行 `deepseek-r1:1.5b`

```shell
root@7ea988ec38c4:/# ollama run deepseek-r1:1.5b
pulling manifest
pulling aabd4debf0c8... 100% ▕████████████████████████████████████████████████████████▏ 1.1 GB
pulling 369ca498f347... 100% ▕████████████████████████████████████████████████████████▏  387 B
pulling 6e4c38e1172f... 100% ▕████████████████████████████████████████████████████████▏ 1.1 KB
pulling f4d24e9138dd... 100% ▕████████████████████████████████████████████████████████▏  148 B
pulling a85fe2a2e58e... 100% ▕████████████████████████████████████████████████████████▏  487 B
# 等待下载完成 更大体量的模型会更久
verifying sha256 digest
writing manifest
success
>>> Send a message (/? for help)
```

测试对话

```markdown
>>> hello
<think>

</think>

Hello! How can I assist you today? 😊

>>> 
```
